{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from keras import Input, layers\n",
    "from keras.models import Model, load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, Callback\n",
    "from keras import backend as K\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer as Detok"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pickle.load(open('data/works_proc.pkl', 'rb'))\n",
    "\n",
    "toks_trn, toks_val, ixs_trn, ixs_val = data['toks_trn'], data['toks_val'], data['ixs_trn'], data['ixs_val']\n",
    "stoi, itos = data['stoi'], data['itos']\n",
    "UNK, PAD, BOS, EOS, max_len = data['UNK'], data['PAD'], data['BOS'], data['EOS'], data['max_len']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16196, 199), (16196, 199), (4050, 199), (4050, 199))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create input and output sequences for the language model\n",
    "X_trn, X_val = ixs_trn[:, :-1], ixs_val[:, :-1]\n",
    "y_trn, y_val = ixs_trn[:, 1:], ixs_val[:, 1:]\n",
    "\n",
    "X_trn.shape, y_trn.shape, X_val.shape, y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16196, 199, 1), (4050, 199, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reshape y in order to use sparse_categorical_crossentropy\n",
    "y_trn_rs = y_trn.reshape(y_trn.shape[0], y_trn.shape[1], 1)\n",
    "y_val_rs = y_val.reshape(y_val.shape[0], y_val.shape[1], 1)\n",
    "\n",
    "y_trn_rs.shape, y_val_rs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define model attributes\n",
    "vocab_size = len(itos)\n",
    "embed_size = 256\n",
    "hidden_size = 256\n",
    "n_rnn_layers = 2\n",
    "dropout = .3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save meta data\n",
    "meta_data = {\n",
    "    'stoi': stoi,\n",
    "    'itos': itos,\n",
    "    'UNK': UNK,\n",
    "    'PAD': PAD,\n",
    "    'BOS': BOS,\n",
    "    'EOS': EOS,\n",
    "    'max_len': max_len,\n",
    "    'embed_size': 256,\n",
    "    'hidden_size': 256,\n",
    "    'n_rnn_layers': 2,\n",
    "    'dropout': .3\n",
    "}\n",
    "\n",
    "pickle.dump(meta_data, open('data/meta_data.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size=vocab_size,\n",
    "                 embed_size=embed_size,\n",
    "                 hidden_size=hidden_size,\n",
    "                 n_rnn_layers=n_rnn_layers,\n",
    "                 dropout=dropout,\n",
    "                 embed_layer=None,\n",
    "                 rnn_layers=None,\n",
    "                 dense_layer=None,\n",
    "                 incl_states_in_output=False):\n",
    "    # Define input tensor for X\n",
    "    X = Input(shape=(None, ), name='X')\n",
    "    \n",
    "    # Embed\n",
    "    if not embed_layer:\n",
    "        embed_layer = layers.Embedding(input_dim=vocab_size, output_dim=embed_size, mask_zero=True, name='embed_layer')\n",
    "    y = embed_layer(X)\n",
    "    \n",
    "    # Feed into RNNs\n",
    "    # Placeholders for states\n",
    "    h0s, c0s = [], []\n",
    "    hs, cs = [], []\n",
    "    for i in range(n_rnn_layers):\n",
    "        # Define input tensor for initial states\n",
    "        h0 = Input(shape=(hidden_size, ), name=f'h0_{i}')\n",
    "        c0 = Input(shape=(hidden_size, ), name=f'c0_{i}')\n",
    "        \n",
    "        if not rnn_layers:\n",
    "            rnn_layer = layers.LSTM(hidden_size, return_sequences=True, return_state=True, dropout=dropout, recurrent_dropout=dropout, name=f'rnn_layer_{i}')\n",
    "        else:\n",
    "            rnn_layer = rnn_layers[i]\n",
    "        \n",
    "        y, h, c = rnn_layer(y, initial_state=[h0, c0])\n",
    "\n",
    "        # Save states\n",
    "        h0s.append(h0)\n",
    "        c0s.append(c0)\n",
    "        hs.append(h)\n",
    "        cs.append(c)\n",
    "    \n",
    "    # Feed the output to the final dense layer\n",
    "    if not dense_layer:\n",
    "        dense_layer = layers.Dense(vocab_size, activation='softmax', name='dense_layer')\n",
    "    y = dense_layer(y)\n",
    "    \n",
    "    # Put together\n",
    "    inputs = [X] + h0s + c0s\n",
    "    if incl_states_in_output:\n",
    "        outputs = [y] + hs + cs\n",
    "    else:\n",
    "        outputs = y\n",
    "    \n",
    "    model = Model(inputs, outputs)\n",
    "    print(model.summary())\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed_layer (Embedding)         (None, None, 256)    2022912     X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "h0_0 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0_0 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rnn_layer_0 (LSTM)              [(None, None, 256),  525312      embed_layer[0][0]                \n",
      "                                                                 h0_0[0][0]                       \n",
      "                                                                 c0_0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "h0_1 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0_1 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rnn_layer_1 (LSTM)              [(None, None, 256),  525312      rnn_layer_0[0][0]                \n",
      "                                                                 h0_1[0][0]                       \n",
      "                                                                 c0_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, None, 7902)   2030814     rnn_layer_1[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 5,104,350\n",
      "Trainable params: 5,104,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compile\n",
    "optimizer = 'adam'\n",
    "loss = 'sparse_categorical_crossentropy'\n",
    "metrics = ['sparse_categorical_accuracy']\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialize states with zeros\n",
    "def init_states(n_obs, hidden_size=hidden_size, n_rnn_layers=n_rnn_layers):\n",
    "    h0s, c0s = [], []\n",
    "    for i in range(n_rnn_layers):\n",
    "        zeros = np.zeros(shape=(n_obs, hidden_size))\n",
    "        \n",
    "        h0s.append(zeros)\n",
    "        c0s.append(zeros)\n",
    "    \n",
    "    return h0s, c0s\n",
    "\n",
    "h0s_trn, c0s_trn = init_states(X_trn.shape[0])\n",
    "h0s_val, c0s_val = init_states(X_val.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add callbacks\n",
    "callbacks = []\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5, verbose=1)\n",
    "callbacks.append(reduce_lr)\n",
    "\n",
    "stopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n",
    "callbacks.append(stopper)\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath='model/model.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
    "callbacks.append(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Other training attributes\n",
    "batch_size = 64\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train\n",
    "hist = model.fit(\n",
    "    x=[X_trn]+h0s_trn+c0s_trn,\n",
    "    y=y_trn_rs,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=([X_val]+h0s_val+c0s_val, y_val_rs),\n",
    "    shuffle=True,\n",
    "    callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload the last checkpoint\n",
    "model = load_model('model/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Extract trained layers\n",
    "embed_layer = model_pkl.get_layer('embed_layer')\n",
    "rnn_layers = [model_pkl.get_layer(f'rnn_layer_{i}') for i in range(n_rnn_layers)]\n",
    "dense_layer = model_pkl.get_layer('dense_layer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "X (InputLayer)                  (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embed_layer (Embedding)         (None, None, 256)    2022912     X[0][0]                          \n",
      "__________________________________________________________________________________________________\n",
      "h0_0 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0_0 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rnn_layer_0 (LSTM)              [(None, None, 256),  525312      embed_layer[1][0]                \n",
      "                                                                 h0_0[0][0]                       \n",
      "                                                                 c0_0[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "h0_1 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "c0_1 (InputLayer)               (None, 256)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "rnn_layer_1 (LSTM)              [(None, None, 256),  525312      rnn_layer_0[1][0]                \n",
      "                                                                 h0_1[0][0]                       \n",
      "                                                                 c0_1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense_layer (Dense)             (None, None, 7902)   2030814     rnn_layer_1[1][0]                \n",
      "==================================================================================================\n",
      "Total params: 5,104,350\n",
      "Trainable params: 5,104,350\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Reconstruct the model with states in the output\n",
    "model_w_states = create_model(embed_layer=embed_layer, rnn_layers=rnn_layers, dense_layer=dense_layer, incl_states_in_output=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "detokenizer = Detok()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predict with a seed phrase\n",
    "def sample_w_pred_prob(pred_probs, temperature=.5, avoid_unk=False):\n",
    "    pred_probs = pred_probs.flatten().astype('float64')\n",
    "    \n",
    "    # Adjust probabilities with temperature\n",
    "    # https://github.com/minimaxir/textgenrnn/blob/master/textgenrnn/utils.py#L16\n",
    "    if temperature == 0:\n",
    "        return pred_probs.argmax()\n",
    "    \n",
    "    log_pred_probs = np.log(pred_probs + K.epsilon()) / temperature\n",
    "    pred_probs = np.exp(log_pred_probs)\n",
    "    \n",
    "    if avoid_unk:\n",
    "        pred_probs[stoi[UNK]] = 0\n",
    "    \n",
    "    pred_probs = pred_probs / pred_probs.sum()\n",
    "    sample_ix = np.random.multinomial(1, pred_probs).argmax()\n",
    "    return sample_ix\n",
    "\n",
    "def gen_seq_w_seed(seed_phrase, max_chars=280):\n",
    "    # Tokenize and map to indices\n",
    "    seed_toks = seed_phrase.split()\n",
    "    seed_toks = [BOS] + seed_toks\n",
    "    seed_ixs = [stoi[tok] if tok in stoi else stoi[UNK] for tok in seed_toks]\n",
    "    seed_ixs = np.array(seed_ixs).reshape(1, -1)\n",
    "\n",
    "    # Initiate states\n",
    "    seed_h0s, seed_c0s = init_states(1)\n",
    "\n",
    "    # Apply model\n",
    "    seed_preds = model_w_states.predict([seed_ixs]+seed_h0s+seed_c0s)\n",
    "    seed_ixs_preds, seed_hs, seed_cs = seed_preds[0], seed_preds[1:3], seed_preds[3:]\n",
    "\n",
    "    # Extract the last predicted token and use it as the seed going forward\n",
    "    seed_ix_pred = seed_ixs_preds[:, -1, :]\n",
    "    seed_ix_pred = sample_w_pred_prob(seed_ix_pred, avoid_unk=True)\n",
    "    seed_tok_pred = itos[seed_ix_pred]\n",
    "\n",
    "    # Generate new words\n",
    "    gen_toks = []\n",
    "    chars = len(seed_phrase)\n",
    "    while seed_tok_pred not in [PAD, EOS] and chars <= max_chars:\n",
    "        gen_toks.append(seed_tok_pred)\n",
    "        seed_preds = model_w_states.predict([np.array(seed_ix_pred).reshape(1, -1)]+seed_hs+seed_cs)\n",
    "        seed_ix_pred, seed_hs, seed_cs = seed_preds[0], seed_preds[1:3], seed_preds[3:]\n",
    "        seed_ix_pred = sample_w_pred_prob(seed_ix_pred, avoid_unk=True)\n",
    "        seed_tok_pred = itos[seed_ix_pred]\n",
    "        chars += len(seed_tok_pred) + 1\n",
    "    \n",
    "    return seed_toks[1:] + gen_toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'it is a truth universally acknowledged,and that he was not at all ashamed of her,and he was preparing to be the earliest of the evening; and she was obliged to repeat the day before they came to the door,and mr . crawford was left to go out,and the more to be ready.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_phrase = 'it is a truth universally acknowledged'\n",
    "gen_toks = gen_seq_w_seed(seed_phrase)\n",
    "detokenizer.detokenize(gen_toks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
