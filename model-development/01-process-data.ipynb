{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import itertools\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.max_rows = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and clean the Gutenberg data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1661600, 4)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works = pd.read_csv('data/works.csv', encoding='latin1')\n",
    "works.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(167990, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "works = works[works['author'] == 'Austen, Jane'].copy()\n",
    "works.reset_index(drop=True, inplace=True)\n",
    "works.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace NAs with paragraph breaks\n",
    "works['text'] = works['text'].fillna('[PARA]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split by paragraph\n",
    "def split_by_paragraph(strings):\n",
    "    # Join strings\n",
    "    strings = ' '.join(strings)\n",
    "\n",
    "    # Split by paragraph break\n",
    "    strings = strings.split('[PARA]')\n",
    "    \n",
    "    # Clean up\n",
    "    strings = [s.strip() for s in strings]\n",
    "    strings = [s for s in strings if s]\n",
    "    return strings\n",
    "\n",
    "works = works.groupby(['gutenberg_id', 'title', 'author'])['text'].apply(lambda strings: pd.Series(split_by_paragraph(strings)))\n",
    "works = pd.DataFrame(works).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    23467.000000\n",
       "mean       386.229301\n",
       "std        488.584749\n",
       "min          1.000000\n",
       "25%         95.000000\n",
       "50%        239.000000\n",
       "75%        508.000000\n",
       "max      14695.000000\n",
       "Name: text, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check paragraph length\n",
    "works['text'].str.len().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20246, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove paragraphs shorter than 50 characters\n",
    "works = works[works['text'].str.len() >= 50].copy()\n",
    "works.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the text data\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('â€™', '\\'', text)\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "works['text'] = works['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_nlp = spacy.load('en_core_web_sm', disable=['tagger', 'parser', 'ner', 'textcat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "txts = works['text'].tolist()\n",
    "toks = []\n",
    "for txt in spacy_nlp.pipe(txts, batch_size=10000, n_threads=4):\n",
    "    toks.append([tok.text for tok in txt])\n",
    "works['toks'] = toks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "works.to_pickle('data/works.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "works = pd.read_pickle('data/works.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16196, 4050)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toks_trn, toks_val = train_test_split(works['toks'].tolist(), test_size=0.2, random_state=0)\n",
    "len(toks_trn), len(toks_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BOS and EOS\n",
    "BOS = '_bos_'\n",
    "EOS = '_eos_'\n",
    "\n",
    "toks_trn = [[BOS] + toks + [EOS] for toks in toks_trn]\n",
    "toks_val = [[BOS] + toks + [EOS] for toks in toks_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Map tokens to indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "UNK = '_unk_'\n",
    "PAD = '_pad_'\n",
    "\n",
    "def create_mapper(toks, max_vocab=100000, min_freq=5, UNK=UNK, PAD=PAD, BOS=BOS, EOS=EOS):\n",
    "    toks_freq = Counter(toks)\n",
    "    \n",
    "    # Create index to string mapper\n",
    "    itos = [s for s, c in toks_freq.most_common(max_vocab) if c >= min_freq]\n",
    "    \n",
    "    # Add special tokens to the front\n",
    "    itos = [PAD, UNK] + itos\n",
    "    \n",
    "    # Create string to index mapper\n",
    "    stoi = {s: i for i, s in enumerate(itos)}\n",
    "    \n",
    "    return stoi, itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1575711"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all tokens from the training data\n",
    "toks_trn_all = list(itertools.chain(*toks_trn))\n",
    "len(toks_trn_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7902, 7902)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create mappers using the training data\n",
    "stoi, itos = create_mapper(toks_trn_all)\n",
    "len(stoi), len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_pad_', '_unk_', ',', '.', 'the', 'to', 'and', 'of', '\"', 'a']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['banners',\n",
       " 'outer',\n",
       " 'complains',\n",
       " 'pupil',\n",
       " 'donkey',\n",
       " 'tragic',\n",
       " 'authors',\n",
       " 'birthday',\n",
       " 'bickerton',\n",
       " '1811']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map tokens to indices\n",
    "ixs_trn = [[stoi[tok] if tok in stoi else stoi[UNK] for tok in toks] for toks in toks_trn]\n",
    "ixs_val = [[stoi[tok] if tok in stoi else stoi[UNK] for tok in toks] for toks in toks_val]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Truncate and pad sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0       7.0\n",
       "0.1      23.0\n",
       "0.2      31.0\n",
       "0.3      41.0\n",
       "0.4      53.0\n",
       "0.5      67.0\n",
       "0.6      83.0\n",
       "0.7     107.0\n",
       "0.8     141.0\n",
       "0.9     205.0\n",
       "1.0    3006.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check sequence lengths in the training data\n",
    "pd.Series([len(ixs) for ixs in ixs_trn]).quantile(np.arange(0, 1.1, .1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick 200\n",
    "max_len = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16196, 200), (4050, 200))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ixs_trn = pad_sequences(ixs_trn, max_len, padding='post', truncating='post', value=stoi[PAD])\n",
    "ixs_val = pad_sequences(ixs_val, max_len, padding='post', truncating='post', value=stoi[PAD])\n",
    "\n",
    "ixs_trn.shape, ixs_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['_bos_ \" perhaps , \" said darcy , \" i should have judged better , had i sought an introduction ; but i am ill - qualified to recommend myself to strangers . \" _eos_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_',\n",
       " '_bos_ now , upon his father \\'s marriage , it was very generally proposed , as a most proper attention , that the visit should take place . there was not a _unk_ voice on the subject , either when mrs . perry drank tea with mrs . and miss bates , or when mrs . and miss bates returned the visit . now was the time for mr . frank churchill to come among them ; and the hope strengthened when it was understood that he had written to his new mother on the occasion . for a few days , every morning visit in highbury included some mention of the handsome letter mrs . weston had received . \" i suppose you have heard of the handsome letter mr . frank churchill has written to mrs . weston ? i understand it was a very handsome letter , indeed . mr . woodhouse told me of it . mr . woodhouse saw the letter , and he says he never saw such a handsome letter in his life . \" _eos_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_ _pad_']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "[' '.join(toks) for toks in np.array(itos)[ixs_val[:2]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "data = {\n",
    "    # Original data\n",
    "    'toks_trn': toks_trn,\n",
    "    'toks_val': toks_val,\n",
    "    \n",
    "    # Processed data\n",
    "    'ixs_trn': ixs_trn,\n",
    "    'ixs_val': ixs_val,\n",
    "    \n",
    "    # Meta data\n",
    "    'stoi': stoi,\n",
    "    'itos': itos,\n",
    "    'UNK': UNK,\n",
    "    'PAD': PAD,\n",
    "    'BOS': BOS,\n",
    "    'EOS': EOS,\n",
    "    'max_len': max_len\n",
    "}\n",
    "\n",
    "pickle.dump(data, open('data/works_proc.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
